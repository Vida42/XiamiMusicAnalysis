第一步，爬歌曲信息：
10.10早开始研究，
对820663首歌进行数据获取（保留orders，song，抓artist，album，album_name）
分成12个（一电脑3进程），一开始10.10下午就只可达到同时10进程，10.12早退化为6进程，10.12晚退化为3进程。10.13早退化成2进程。

过程中遇到问题：1.有些歌曲页面重定向至虾米音乐人。
2.有些歌曲页面没了直接404
3.玄学·有的时候好好的爬着没问题。一动界面（比如看一下还剩多少，切换console看一下都好着没）立刻就不行了。

所以需要针对1和2，用自己的程序再走一遍：
404的标记artist，album，album_name都为404_deleted；
302的标记artist可得，不去头了，带着http：…保存，album，album_name都为302_redirected

第一步+：整理第一步的数据，得到专辑和艺人信息
先和已有信息对比，检查是否爬全。无误后将获取的数据放入MySQL，（orders，song，song_name会重复出现两次，先不管），分别对album和artist去重另存，album表有album_name（可以考虑继续附一个orders项，避免重复工作改scrapy框架内容）。

第二步，爬专辑信息：
分两部分。
a。404的和302的置到一个txt内；
b。对张专辑进行数据获取（保留orders，album，抓lan，releasedtime，genre（如果有））。很多项genre的将他们用+号拼起来
（先试一下没有的抓出来会不会保留位置——把genre往前放放）

第三步，爬艺人信息：
分三部分。
a。对普通艺人。普通解析，留orders，artist，抓atrist_name，genre（如果有）
b。对虾米音乐人。虾米音乐人解析，留orders，artist，抓atrist_name，genre（如果有）
这个还分成由demo而来的虾米音乐人（音乐人一栏直接是网址），和留在普通音乐人中的虾米音乐人（音乐人一栏是id）。
c。404的，置到一个txt内；

第四步，爬风格名：
直接去风格页面爬下genre，genre_name，所属大类。

第五步，爬用户信息：
直接把那一大串字段先撸下来再说，详细的拆分看另一个文件吧。
